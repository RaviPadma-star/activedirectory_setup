1. In case your quires are running slow, if the application running slow, if your cpu utilization more than 90%, if your memoery is more than 90% utilization, all these features of impacting the sql server, the configuration of tempdb issues, server configuration, normal road bloacks. impact the performance of application


tell me one thing--> now one query is running since 5 hours--> now tell me do we have performance issue here or we don't have performance issue here:-> 

--> now basically it depends --> you are running a backup query of 5tb, do you think it will completed in 2 seconds -> no its depends on data
--> long running session are comman in sql server
--> if query is running slow you have to compare previous time, or earlier it run for less time now its running more time then there is performance issue

--> so what and all issues will see on performance issues on regular basis-->
1. cpu more than 90%
2. memory more than 90%
3. blockings
4. some time temp full issues, tempdb contentions, blockings, deadlock and incase user will complaint hey, query is running slow, app is running slow, when ever they click the tab it running slow.

so generally we do healt check, sql server eb=ven if we tool care of all sql servers at our end, configuration best possible setting even though we did it- but still the query is running slow means what might be the reason -> in case network is slow in case os drives, storage the read and write operation are slow then also will get performance issues, these thing are not control by purselves

--> generally performce issues, what kind of health check we do
   --> health checks means -> cpu utilization, memory utilization, blocking drives spaces including,, cdrive, data drive, log drive, backup drives, event viewer,  you have to check all db status, weather db are up and running or not, sql services are running or not


--> lets go to the cpu utilization
	-> task manager --> ill keep monitoring
	-> imagine, you running a backup query, you know that backup query are performance killers- so if the sql server is busy with some other tranactions, at the same time you took the backup, suddenly there will be a spike in the resources, your cpu, memory, disk I/o

	--> in the organization, generally we get cpu utilization, memory utilization, disk utilization
	--> once 90% usage is hit will get alert, so on server, now you login into yhe server, yoy get a mail stating that so on server cpu utilization is 95%, now you login automatically go up and down if you getting lot of performcae issue, there are 2 factors one is didn't setup the system properly, means you are following but recommended practices setting.
2--> the development team is very poor

-> if cpu 90% utilization, once login to yhe server, just wait for 15 to 20 mins, automatic solution, will be there, it will come down, if not we have to trouble shoot the thingd
	--> cpu, memory , blockings are common
	--> troubleshooting-->  login to the server open task manager, so now what have to do --> after watching 15 to 20 min the issues is not fixes--> imagine its cpu issue now click on cpu tab once, you can see ascending and decending order, on the top we can see which process like window and other releated taking more cpu memeroy disks, means we don't do anything its not in our hand, simply inform to windows tems, windows team will take care of it

--> if the top sql server is there then we have to takecare of it
	--> if sql server is taking more process means we have to check -> which sql server is more consuming the process. which instance is taking--> so once you get the instance name then we will connect to the sql server instance
--> in case if we have blocking, it will effect the performance issue, Blocking are very common in sql, because lot of users access, the resources at a time, which create a logs on resources, until the transaction is going to completed, the logs wont be released, so the other person have to wait very comman, on busy system, we can see many blockings-> blocking are come and go automatically.


how to check blocking:-->
cmd--> sp_who2 --> we can see blk by 
ex: 45 - is blk by session id is called lead blocker or head blocker

--> how to find lead blocker
   --> google -> sql script to find the lead blocker -> pinal dave--> open brent ozcr

--> diff state of transaction means status, suspended, sleeping, backgroung, runnable

--> I want to see exclusive, blocking
	--> select * from sys.sysprocesses where blocked <>0

--> sp_who2 is active
it will give error, because its custom script, we have to deploye in stored procudre, in case blocking are there, what is the solution, you can see login, Anusha session is blocking go to the teams Anusha or send email, your session is blocking other session, is that ok kill your sessions or you going to cancel your session, if she say yes you can go head and kill it. otherwise Anusha with cancel the window and blocking will be completed. once lead blocker is killed.
-> in some secenrio, Anusha is not responding after taking the approval of Anusha manager, then you can kill the sessiom, without approval, don't kill the sessions


Deadlock--> is a one type of blocking, so imagine if Anusha is there and Lalitha they both are running same query on the same object, at the same time they running so one session, if 2 session are blocked by each other is called deadlock  -->

--> the impact of dead lock is its create the dead lock dump
--> how to find deadlocks
--> for this we enable trace flags
--> how to enable trace flags--> using query called 
	-->DBCC trancon
--> we havve to 2 trace flags
	-->dbcc trancestatus

--> how can we congifure dbcc, ebale for globally--> sql server config manager
	--> dbcc traceon (1222) --> to track dead lock
	--> dbcc traceoff(1222)  -> 1204 -to trace flag help to find or track the dead locks

--> to see dead locks -> first we need to enable the transon(1222),
				--> dbcc traceon(1222)
				--> dbcc traceon(1204)

then

--> dead lock auto resolved, out of 2 transaction the highest priority will run and least priority transaction killed automatically

--> if you keep getting dead locks, might generate, deadlock dump, deadlock dumo can generate, dead lock schedular, it might be restart the sql server, this secenerion, if want to fix the issue, you have to check the session running by Lalitha and Anusha check both session

--> if the continuously getting the dead locks before the it generates, login the server using sql profiler -> tols-> sql server profiler--> if you enables the profiler, it keeping profiler enabled for longtime, it will get performance issue

--> if you are team lead ask you to check dead lock, you know the by every week the dead lock generating by 3 pm, you login to the server by 2:55--> tools-> sql-profiler-> create a trace on

--> sql profiler is a mandotaory tool you can monitor, the things are running using sql-profiler, profiler is a performace killer you cant enable for long time-> only during some secenrios like dead lock, to track it --> select the event selection tab -> right side Check mark show all events--> epands locks--> run it running -> now I can generate the graph --> google script to generate dead locks in sql server--> brentozar.om

--> select * from sys.dm_exec_requests

and also go to sql server error log
--> management-> expand-> sql serverlogs
--> for global adding trace flags sessions for trace on --> go sql --> configuration manager--> select insance, right click-> properties--> startup-paramater--> -T1222 --> click add
					-T1204 --> click add

but adding the trace log from the configuration manager-required restart of the sql server

--> if enable trace flag from locally no need of restart the sql server

--> it continuously dead locks are coming we can connect to the customer or developers to re-writhe logics, solutions

-> if our session is killed, using dead lock immediately, will get update the seesion will klled the victim



--> how to deploy sp_whoisactive
	--> gogle -> sp_whoisactive doqnload
copy and paste on desktop server double click open with ssms -k execute


--> if you kill any section, it goes to roll back state
--> lets discuss other reasons cause the performance issue

--> if any job are running since hours, because of performance issue, it crossing the business hours
--> go to sql server agent --> job activity monitor

--> if you executing the status, in activity monitor check which jobs are running, application related jobs, are ok,  if this running in business hours--> but any maintance related jobs are backup, jobs restore jobcheck db jobs--> index rebuiliding jobs, index re-organizing jobs, update statices jobs there are all maintance jobs, these jobs are running in business hours, will ger performance issue, kill the job if necessary

--> check -> job--properties -> viewhistory--> duration--> then decide--> compare the timings

--> backup jobs
--> check db jobs
--> dbcc update statistics
--> indexing job              -> non-business hours if theres are running in business hours means its a performce issue


next is configuration--> while installing sql server, people may forget enable the configuration setting so if you don't eb=nable the config setting, generally the query will run sloqly

--> what kind of config setting is enabled

-> the config setting are diff for cpu, and memory so it is cpu issue you have see config setting

-> lets discuss memory in 95% you have to check configuration setting

--> for memory there is configuration setting, max server memory
--> go to instance properties--> memory
   ex 2147483647 2 peta byts

--> 80% of machine wil allocate sql server
this is post installation setting

--> if you are machine having 32 gb of memory maximum memory I can allocate to the sql server ->32gb of 80%
--> incase other external services are there like ssis, ssrs -- in this case 60% of max memory can allocate to the sql server

--> 40% bids will use this allocation
--> this is on the fly setting -means immediately it will effect means no -need to restart
in case memory is 90% we see a quick troubleshooting you know instance-> propertirs-memory->26000 to 24000 immedietly solution--> but it temp it will save us

--> once the issue resolved then set the default values as same

--> if the cpu is more utilization go to instance --> properties-> advanced 
--> max degree of parallelism
--> cost threshold for parallesim
--for every query it execute the plans behind
--> each plans have some cost 

plan 1 ->1min 50% resources
plan2- 2mins
plan3 - 30 sec 100% resources

this plan can select for execution of query

this will stored in plan cache

--> LRU -- least reacently used plans
MRU--> most recently used plans

--> next you run same query, don't prepare any plans for seperatly it will stored in plan cache
--> if you are not running the query, it will dropeed from lru

--> if you want to execution plan there are 2 types of execution plan
1. estimated execution plam
2.actual execution plan

where to check:
sp_whoisactive

there is button called ctrl+m --> actual execution plan, crtl + l --> estimated execution plan


let come back to cpu configuration, parallelism
--cost thershld for paralleslim
max degree of parillesim
means cot means query cost--> threshold means--> means maximum value parallism means--> simentonusly

in case query cost is more than 5 percent
then go to parallelisum --> one is serialism, 2 is parellesium
if query cost is less than 5 percentage it goes to serialisim


if more than 5 percent it goes to parrallesim the idle valu is 5 only

serialism is best for some secenerios and parrelism is best for some secenerios

this  values will tell you if go for serialism or parrelism''now max degree of parrallism


maxdop 1

what is ctp and max dop
cost threshold parallism -ctp
what it means --> for example --> if I want to do parallel thing

if parallelism is needed, now how many cpu cores has to be utilized will decide by maxdop if parallesim is need how many cores we needed --> depends on machine core cpu only

--> if you have 4 cores means, the max dop is used 4 cores for parallelism

--ctp -- will decided weather it goes to serialism on parallism
-- maxdop will decide how many cores should use of parallism, it purely depends on machine cores


Dirty Pages: Dirty pages is nothing but modifying the pages in memory is called dirty pages

ex: when you read or write something un-commited transaction when you write in the log file it will write a page which ever modified page is called dirtypages

when you fire a sql query, first it will check any semantic error are there it will parse it-- if table will be existing means what collection of pages imagine if customer table sitting on 100 pages and keep into the memory and from there we gone read it correct in case you doing any insert statement, the page that you modified the page will be loaded into memeroy, now you modify the recors, now the page is changed right, previous that modified page is called dirty page


--> lazt writer --> wont manage automatically, when there is more huge memory, pressure will it manage

--> maxdop means what how cpu cores must be utilized that will decide maxdop
the idle value is the recommande value is 8

--> if you server as more cores, where to check go to performance task manager or simply cmd--> systeminfo or system information--will see a option as processor tab



so now lets discuss about the indexes:

what is indexes, how to see the indexes how may types of indexes are there, where we can see the indexes, how to create indexes, what is the imp of indexes

--> INDEXES
	--> indexes index will be help you for selelcted query only, only for select query whre condition where clause


--> index also an object, index will helps in searching data fast, indes improve the performance of slect query, index also some storage, index has its own page, do not create indexes on tables having min. 1000rows, no need to create any index on the table having minimum 1000 rows, it will give give you negative performance. on a table we can create maximum 999 indexes, for sql server 2005 the value is 249

2 types of indexes
1. clustered indexes
2. non-clustered indexes

when you create a clustered indexed based on ley, on any column so the the records are orgainsed based on clustered ky values

-->when you created cluster index, it re-organized the records, it will drop the table, re-create the table based on the clustered index column
--> creating clustering indexing are downtime activity or no down time activity

it has to re-arrange the table it will go to tempdb from there sql server the whole operation take place in tempdb, when you trying to create a tabke or cluster index, the whole table move into tempdb from there it will re-arrange the records cluster index are mainly generate on ids

--> to crate the clustered indexes pre-req

you should have primary key, based on the key value. it is going to re-arrange all the record
-> if you have primary key on the table clustered index will be created automatically

-- where can we see the indexes, go the database--> go to tables--> expand index double click--> pk_department(clusterd indexes)

Non -clustered index--> it does not re-arrange the record. the records will be same as it is but there is sperate column called intermediate key it will store the addres of each record in case while searching the data it will simply refers the address guys it will manage the non clustered index

--> Generally sometimes while running the query, we may face missing indexes cause the performance issue

--> how to check missing indexes
--> select * from sys.dm_db_missing_index_details and also we can use execution plan

--> in case usr is complaing hey ravi this query running very solw what we have to do 

-> take that query from user, we will do all health check from our side ntg found
--> so will take the wuery from customer, we will use what and tables including in the where condition, weather the column are part of indexes are not will check it

--> search for images in goggle

terminology--> in interwiew sometimes they will ask you --> what is heap--> a table which has no clustered indexes created, on it is called heap
when search is performed on a heap, it always going to ba full table scan, this scan are very dangerous for sql sever performance (large tables)
--> selct * from sys.indexes where index_id = 0

--> index seek--> seek will not do full table scan, it will touch the exact colums will search the data based on index keys index scan is equal to table scan

index scan is equal to the table scan

covering index: interview --> in the non-clusterd index if we cover all the columns then it is called covering index..
--> if the book size is increasing defently the index pages will increase right on the same way --> index page is also one kind of page this page how much index page must have be fulled, is called index fullfactor --> if index page is completely full it will create excessive page splits -> if its create execessive splits then performance will be de-graded
--> so best practice is keep 20% free space in each page that is called index fill factor
--> how to do that, go to instance properties, go to database setting-> default index fill factor -> zero
that means what will will define the freee space in zero means its disabled
--> we will use 100% percentage-> ok if index page 100% full it will create execussive split, if excessive splits are there, they are going to degrade the performance issue, the idle values I 80%--> it will occupy 800% remaining 20% will be free only on index page not data pages --> this is the post installation steps


